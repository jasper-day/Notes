{
  "hash": "6c032950718d874f492647bae8dc4257",
  "result": {
    "markdown": "---\ntitle: Numerical Methods for Integration\nauthor: Jasper Day\ndate: Wed 12/14/2022 \ncode-fold: show\n---\n\nThe *integral* $\\int f(x) dx$ comes to us from mathematics as the antiderivative of a function. That is, you find\n\n$$\n\\int_a^b f(x) dx = F(b) - F(a),\n$${#eq-integral}\n\nwhere \n\n$$\nf(x) = \\frac{dF(x)}{dx}.\n$${#eq-antid}\n\nThis mathematical interpretation is often fine for finding exact solutions, but presents problems. Some $f(x)$ require complicated operations to integrate analytically, and some are downright impossible, like the error function \n$e^{-x^2}$. Computerized integration, however, can be done much more simply. The usual method is to break up @eq-integral into smaller integrals, which are evaluated individually:\n\n$$\n\\int_a^b f(x) dx = \\int_{x_0}^{x_1} f(x) dx + \\int_{x_1}^{x_2} f(x) dx + \\int_{x_2}^{x_3} f(x) dx + ... + \\int_{x_{n-1}}^{x_n} f(x) dx\n$${#eq-numerical}\n\nThese smaller integrals can then be approximated in different ways.\n\nFor the following examples we will take the integral\n\n$$\n\\int_0^t v(t)dt,\n$$\n\nwhere $v(t)$ is a velocity function\n\n$$\nv(t) = 2te^{t^2}\n$$\n\nThen the analytic solution of our integral equation on the interval [0,1] is given by\n\n$$\n\\int_0^1 v(t) dt = \\left. e^{t^2} \\right|_{t=0}^{t=1} = e - 1 \\approx 1.71828...\n$$\n\n# The Trapezoidal Rule\n\nFor each $x_i,~ x_{i+1}$ pair, approximate the function $f(x)$ as a straight line connecting\n$f(x_i), ~ f(x_{i+1})$. The equation of this line is\n\n$$\n\\begin{align}\nf^*(x) &= f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i}(x - x_i) \\\\\n&= f(x_i) + m(x - x_i)\n\\end{align}\n$$\n\nwith $m = \\frac{f(x_{i+1} - f(x_i))}{x_{i+1} - x_i}$\n\nwhich we can integrate:\n\n$$\n\\begin{align}\n\\int_{x_i}^{x_{i+1}} f^*(x) &= \\left[ xf(x_i) + \\frac{1}{2}mx^2 - x_imx\\right]_{x=x_i}^{x=x_{i+1}}\\\\\n&= (x_{i + 1} - x_i) f(x_i) + \\frac{1}{2} m x_{i+1}^2 - \\frac{1}{2}mx_i^2 + mx_i^2 - mx_{i+1}x_i \\\\\n&= (x_{i + 1} - x_i) f(x_i) + \\frac{1}{2}m\\left( x_{i+1}^2 - 2x_ix_{i+1} + x_i^2\\right) \\\\\n&= (x_{i + 1} - x_i) f(x_i) + \\frac{1}{2}m \\left(x_{i+1} - x_i\\right)^2,\n\\end{align}\n$$\n\nwhich is the area enclosed by the trapezoid in @fig-trapezoid.\n\n![](images/trapezoid.jpg){#fig-trapezoid}\n\nThis trapezoidal approximation can be easily implemented in python:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom math import exp\nfrom numpy import arange\n\nA = 0\nB = 1\ndx = 0.01\n\nx = arange(A, B + dx, dx)\n\nf = lambda x: 2 * x * exp(x ** 2)\n\ndef cumtrapz(x,f):\n    def trapezoid(x, f, index):\n        xi = x[index]\n        xj = x[index + 1]\n        deltax = xj-xi\n        m = (f(xj) - f(xi))/(deltax)\n        return (deltax) * f(xi) + 0.5 * m * (deltax)**2\n    trapezoids = [trapezoid(x,f,index) for index in range(len(x)-1)]\n    # i love list comprehensions\n    # and cumtrapz (with apologies to MatLab)\n    return sum(trapezoids)\n\nprint(cumtrapz(x,f))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.7184010731812909\n```\n:::\n:::\n\n\nNote that the trapezoidal sum contains the correcting term $1/2 m(x_{i+1}-x_{i})^2$, which quickly goes to zero as \n$\\Delta x$, the difference in $x_{i+1}$ and $x_i$, diminishes.\n\nThis suggests that a close approximation of the result from the trapezoidal rule can be obtained by taking the sum from either side:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef cumleft(x,f):\n    def leftint(x, f, index):\n        xi = x[index]\n        xj = x[index + 1]\n        deltax = xj-xi\n        return (deltax) * f(xi)\n    leftints = [leftint(x,f,index) for index in range(len(x)-1)]\n    return sum(leftints)\n\nprint(cumleft(x,f))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.6912182548967005\n```\n:::\n:::\n\n\nIndexing from the left will undershoot an increasing function, and indexing from the right will overshoot.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef cumright(x,f):\n    def rightint(x, f, index):\n        xi = x[index]\n        xj = x[index + 1]\n        deltax = xj-xi\n        return (deltax) * f(xj)\n    rightints = [rightint(x,f,index) for index in range(len(x)-1)]\n    return sum(rightints)\n\nprint(cumright(x,f))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.7455838914658814\n```\n:::\n:::\n\n\nObviously, the trapezoidal approximation is better than either the approximation with constant steps from the left or right. In fact, `cumtrapz` can be obtained simply by averaging `cumleft` and `cumright`:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nprint(\"Value from trapezoidal sum:\")\nprint(cumtrapz(x, f))\nprint(\"Average of left and right integrals:\")\nprint((cumleft(x, f) + cumright(x, f))/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nValue from trapezoidal sum:\n1.7184010731812909\nAverage of left and right integrals:\n1.7184010731812909\n```\n:::\n:::\n\n\n# The Midpoint Method\n\nA better approximation of the value of the function can be found by creating a rectangle at the midpoint of the subintervals $[x_i, x_{i+1}]$:\n\n![](images/midpoint.jpg){#fig-midpoint}\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef cummid(x,f):\n    def midint(x,f,index):\n        xi = x[index]\n        xj = x[index + 1]\n        dx = xj - xi\n        return dx * f(xi + dx/2)\n    midints = [midint(x,f,index) for index in range(len(x) - 1)]\n    return sum(midints)\n\nprint(cummid(x,f))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.718222207111352\n```\n:::\n:::\n\n\nAs you can see, the midpoint approximation is a little closer to our desired value of $1.71828...$ than the trapezoidal approximation.\n\nFurther methods of numerically approximating integrals, such as [Simpson's Rule](https://en.wikipedia.org/wiki/Simpson%27s_rule) and [Gaussian integration](https://en.wikipedia.org/wiki/Gaussian_quadrature) exist and are easily implemented.\n\n",
    "supporting": [
      "integration_files"
    ],
    "filters": [],
    "includes": {}
  }
}